import streamlit as st
import os
from openai import OpenAI
from langchain_openai import OpenAIEmbeddings
from langchain_community.vectorstores import FAISS
import uuid
from datetime import datetime
import streamlit.components.v1 as components

# --- å®šæ•° ---
SIMILARITY_THRESHOLD = 0.7 # é¡ä¼¼åº¦ã®ã—ãã„å€¤
REQUEST_LOG_FILE = "shun_requests.log"

# --- åˆæœŸè¨­å®š ---
st.title("ã„ã¤ã§ã‚‚ã—ã‚…ã‚“ã•ã‚“")

# Streamlitã®secretsã‹ã‚‰APIã‚­ãƒ¼ã‚’è¨­å®š
try:
    api_key = st.secrets["OPENAI_API_KEY"]
    client = OpenAI(api_key=api_key)
except KeyError:
    st.error("OpenAI APIã‚­ãƒ¼ãŒ.streamlit/secrets.tomlã«è¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
    st.stop()

# --- å®šæ•° ---
KNOWLEDGE_BASE_DIR = "google_api/google_docs_source" # æ¤œç´¢å¯¾è±¡ã‚’é™å®š

# --- FAISSã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®ãƒ­ãƒ¼ãƒ‰ ---
FAISS_INDEX_PATH = "data/faiss_index"

@st.cache_resource
def load_faiss_index(path):
    """FAISSã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’åˆ©ç”¨ï¼‰"""
    try:
        embeddings = OpenAIEmbeddings()
        return FAISS.load_local(path, embeddings, allow_dangerous_deserialization=True)
    except Exception as e:
        st.error(f"çŸ¥è­˜ãƒ™ãƒ¼ã‚¹ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
        return None

db = load_faiss_index(FAISS_INDEX_PATH)

# ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–
if "messages" not in st.session_state:
    st.session_state.messages = [{
        "role": "assistant",
        "content": "åƒ•ã¯ã—ã‚…ã‚“ã•ã‚“ã®ã‚¯ãƒ­ãƒ¼ãƒ³ã§ã™ã€‚ã—ã‚…ã‚“ã•ã‚“ãŒæ•™ãˆã¦ãã‚ŒãŸæƒ…å ±ã‚’å…ƒã«ã‚ãªãŸã®è³ªå•ã«ç­”ãˆã¡ã‚ƒã†ã‚ˆï¼å¼•ãå¯„ã›ã®æ³•å‰‡ãƒ»ã‚ªãƒ¼ãƒ€ãƒ¼ãƒãƒ¼ãƒˆã‚’å­¦ã¶ä¸­ã§ç–‘å•ã‚„äººç”Ÿç›¸è«‡ãªã©ã‚ã‚Œã°ãªã‚“ãªã‚Šãƒãƒ£ãƒƒãƒˆã‹ã‚‰æ•™ãˆã¦ãã ã•ã„ï¼\n\nâ€»ã‚ãªãŸãŒè³ªå•ã—ãŸã“ã¨ã¯ã„ã‹ãªã‚‹ã“ã¨ã§ã‚ã£ã¦ã‚‚ã€ã—ã‚…ã‚“ã•ã‚“ã‚„ä»–ã®äººã«ã¯è¦‹ãˆãªã„ã‹ã‚‰ã€å®‰å¿ƒã—ã¦ã­ï¼",
        "sources": [],
        "id": str(uuid.uuid4()),
        "offer_request": False, # ãƒªã‚¯ã‚¨ã‚¹ãƒˆææ¡ˆä¸­ã‹ã©ã†ã‹ã®ãƒ•ãƒ©ã‚°
        "request_sent": False, # ãƒªã‚¯ã‚¨ã‚¹ãƒˆé€ä¿¡æ¸ˆã¿ã‹ã©ã†ã‹ã®ãƒ•ãƒ©ã‚°
        "coaching_mode": False, # è³ªå•ã‚³ãƒ¼ãƒãƒ³ã‚°ä¸­ã‹ã©ã†ã‹ã®ãƒ•ãƒ©ã‚°
    }]
if "advice_mode" not in st.session_state:
    st.session_state.advice_mode = False

# --- ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•° ---
def log_request(query_to_log):
    """ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã‚’ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã«è¨˜éŒ²ã™ã‚‹"""
    with open(REQUEST_LOG_FILE, "a", encoding="utf-8") as f:
        log_entry = {
            "timestamp": datetime.now().isoformat(),
            "request_content": query_to_log,
        }
        f.write(str(log_entry) + "\n")

def rephrase_and_log_request(user_prompt):
    """ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã‚’ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ã«é…æ…®ã—ã¦ãƒªãƒ•ãƒ¬ãƒ¼ã‚ºã—ã€ãƒ­ã‚°ã«è¨˜éŒ²ã™ã‚‹"""
    try:
        rephrase_system_prompt = (
            "ã‚ãªãŸã¯ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‹ã‚‰ã®è³ªå•ã‚’ã€ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ã«é…æ…®ã—ã¤ã¤ã€ã‚³ãƒ¼ãƒã§ã‚ã‚‹ã€Œã—ã‚…ã‚“ã•ã‚“ã€ã¸ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆã¨ã—ã¦è¦ç´„ã™ã‚‹ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚"
            "ä»¥ä¸‹ã®ãƒ«ãƒ¼ãƒ«ã«å¾“ã£ã¦ã€è³ªå•ã‚’1æ–‡ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆã«å¤‰æ›ã—ã¦ãã ã•ã„ã€‚\n"
            "ãƒ»ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å€‹äººçš„ãªè©±ã‚„å›ºæœ‰åè©ã¯çµ¶å¯¾ã«å«ã‚ãªã„ã§ãã ã•ã„ã€‚\n"
            "ãƒ»ã‚ãã¾ã§ä¸€èˆ¬çš„ãªç›¸è«‡ã‚„è³ªå•ã®å½¢ã«ã—ã¦ãã ã•ã„ã€‚\n"
            "ãƒ»å…ƒã®è³ªå•ã®æ„å›³ã‚„æ ¸ã¨ãªã‚‹ãƒˆãƒ”ãƒƒã‚¯ã¯ç¶­æŒã—ã¦ãã ã•ã„ã€‚\n\n"
            "ä¾‹1ï¼šã€ã€‡ã€‡ã•ã‚“ï¼ˆå§‰ï¼‰ã¨ã®é–¢ä¿‚ã§ã„ã¤ã‚‚ã‚¤ãƒ©ã‚¤ãƒ©ã—ã¦ã—ã¾ã„ã¾ã™ã€‚ã©ã†ã™ã‚Œã°ã„ã„ã§ã™ã‹ï¼Ÿã€â†’ã€å®¶æ—é–¢ä¿‚ï¼ˆç‰¹ã«å§‰å¦¹ï¼‰ã®æ‚©ã¿ã«ã¤ã„ã¦ã€é–¢ä¿‚ã‚’æ”¹å–„ã™ã‚‹ãŸã‚ã®ã‚¢ãƒ‰ãƒã‚¤ã‚¹ã‚’æ±‚ã‚ã¦ã„ã¾ã™ã€‚ã€\n"
            "ä¾‹2ï¼šã€å‰¯æ¥­ã§æœˆ5ä¸‡å††ç¨¼ããŸã„ã®ã§ã™ãŒã€ä½•ã‹ã‚‰å§‹ã‚ã‚Œã°ã„ã„ã‹ã‚ã‹ã‚Šã¾ã›ã‚“ã€‚ã€â†’ã€å‰¯æ¥­ã§ã®åç›ŠåŒ–ï¼ˆæœˆ5ä¸‡å††ç›®æ¨™ï¼‰ã«é–¢ã™ã‚‹å…·ä½“çš„ãªå§‹ã‚æ–¹ã«ã¤ã„ã¦ã®è³ªå•ãŒã‚ã‚Šã¾ã™ã€‚ã€"
        )
        
        response = client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": rephrase_system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            stream=False,
            temperature=0.2,
        )
        rephrased_query = response.choices[0].message.content or "ãƒªã‚¯ã‚¨ã‚¹ãƒˆã®è¦ç´„ã«å¤±æ•—ã—ã¾ã—ãŸã€‚"
        
        log_content = f"[è‡ªå‹•æ¤œçŸ¥] {rephrased_query}"
        log_request(log_content)
        st.toast("ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’è‡ªå‹•è¨˜éŒ²ã—ã¾ã—ãŸğŸ“")

    except Exception as e:
        log_request(f"[è‡ªå‹•æ¤œçŸ¥ã‚¨ãƒ©ãƒ¼] è³ªå•ã®è¦ç´„ã«å¤±æ•—ã—ã¾ã—ãŸã€‚Error: {e}")
        st.error(f"ãƒªã‚¯ã‚¨ã‚¹ãƒˆã®è‡ªå‹•ãƒ­ã‚°è¨˜éŒ²ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")


# --- ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®è¡¨ç¤º ---
for idx, msg in enumerate(st.session_state.messages):
    avatar = "assets/avatar.png" if msg["role"] == "assistant" else None
    with st.chat_message(msg["role"], avatar=avatar):
        st.markdown(msg["content"])
        # --- å‚ç…§å…ƒã¨ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯æ©Ÿèƒ½ã®è¡¨ç¤º ---
        if msg["role"] == "assistant" and msg.get("sources"):
            with st.expander("å‚ç…§å…ƒãƒ•ã‚¡ã‚¤ãƒ«"):
                for i, source_item in enumerate(msg["sources"]):
                    if isinstance(source_item, tuple) and len(source_item) == 2:
                        source_doc, score = source_item
                        source_key = source_doc.metadata.get('source', 'N/A')
                        st.markdown(f"**ãƒ•ã‚¡ã‚¤ãƒ«å:** `{source_key}`")
                        st.markdown(f"**é¸æŠç†ç”±:** ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã¨å†…å®¹ãŒé¡ä¼¼ã—ã¦ã„ã‚‹ãŸã‚ (é¡ä¼¼åº¦ã‚¹ã‚³ã‚¢: {score:.4f})")
                        st.text_area("å‚ç…§ç®‡æ‰€:", value=source_doc.page_content, height=100, disabled=True, key=f"source_content_{msg['id']}_{i}")
        
        # --- ãƒªã‚¯ã‚¨ã‚¹ãƒˆ/ã‚¢ãƒ‰ãƒã‚¤ã‚¹ãƒœã‚¿ãƒ³ã®è¡¨ç¤º ---
        if msg.get("offer_request") and not msg.get("request_sent"):
            col1, col2 = st.columns(2)
            with col1:
                if st.button("ã—ã‚…ã‚“ã•ã‚“ã«ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’é€ã‚‹", key=f"request_button_{msg['id']}", use_container_width=True):
                    # ã‚³ãƒ¼ãƒãƒ³ã‚°ãƒ¢ãƒ¼ãƒ‰ã‚’é–‹å§‹ã™ã‚‹
                    st.session_state.messages[idx]["request_sent"] = True # ãƒœã‚¿ãƒ³ã‚’æ¶ˆã™ãŸã‚ã«é€ä¿¡æ¸ˆã¿ã«ã™ã‚‹
                    st.session_state.coaching_mode = True
                    
                    # ã‚³ãƒ¼ãƒãƒ³ã‚°é–‹å§‹ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¿½åŠ 
                    st.session_state.messages.append({
                        "role": "assistant",
                        "content": "ã‚ã‹ã£ãŸï¼ãã—ãŸã‚‰ã€ã©ã‚“ãªè³ªå•ã‚’ã—ã‚…ã‚“ã•ã‚“ã«é€ã‚ã†ã‹ï¼Ÿè³ªå•ãŒæµ®ã‹ã°ãªã„æ™‚ã¯åƒ•ãŒã‚µãƒãƒ¼ãƒˆã™ã‚‹ã‹ã‚‰ã€é æ…®ãªãã„ã£ã¦ã­ã€‚",
                        "id": str(uuid.uuid4())
                    })
                    st.rerun()
            with col2:
                if st.button("ã‚¯ãƒ­ãƒ¼ãƒ³ã—ã‚…ã‚“ã•ã‚“ã®ã‚¢ãƒ‰ãƒã‚¤ã‚¹ã‚’èã", key=f"advice_button_{msg['id']}", use_container_width=True):
                    st.session_state.messages[idx]["request_sent"] = True # ãƒœã‚¿ãƒ³ã‚’æ¶ˆã™
                    st.session_state.advice_mode = True
                    st.rerun() # advice_modeã‚’ãƒˆãƒªã‚¬ãƒ¼ã«å†å®Ÿè¡Œ


# --- ã‚¢ãƒ‰ãƒã‚¤ã‚¹ãƒ¢ãƒ¼ãƒ‰ã®å¿œç­”ç”Ÿæˆ ---
if st.session_state.get("advice_mode", False):
    st.session_state.advice_mode = False # ä¸€åº¦ä½¿ã£ãŸã‚‰ãƒªã‚»ãƒƒãƒˆ
    with st.chat_message("assistant", avatar="assets/avatar.png"):
        message_placeholder = st.empty()
        full_response = ""

        # ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹å…¨ä½“ã‚’ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã¨ã—ã¦å½¢æˆ
        context_docs = []
        if db:
            # FAISSã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‹ã‚‰ã™ã¹ã¦ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆIDã‚’å–å¾—ã—ã€ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’å–å¾—ã™ã‚‹
            docstore = st.session_state.db.docstore
            all_doc_ids = list(docstore._dict.keys())
            retrieved_docs = [docstore.search(doc_id) for doc_id in all_doc_ids]
            # ä¸è¦ãªNoneã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
            retrieved_docs = [doc for doc in retrieved_docs if doc is not None]

            # å–å¾—ã—ãŸãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’çµåˆã—ã¦ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’ä½œæˆ
            context = "--- å‚è€ƒãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹ ---\n"
            for doc in retrieved_docs:
                if doc: # å–å¾—ã§ããŸãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®ã¿è¿½åŠ 
                    context += f"ãƒ•ã‚¡ã‚¤ãƒ«å: {doc.metadata.get('source', 'N/A')}\n"
                    context += doc.page_content + "\n---\n"
        
        # ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’èª­ã¿è¾¼ã‚€
        try:
            with open("docs/system_prompt.md", "r", encoding="utf-8") as f:
                system_prompt = f.read()
        except FileNotFoundError:
            st.warning("docs/system_prompt.md ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
            system_prompt = "You are a helpful assistant."

        # æ¤œç´¢ã—ãŸã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«çµåˆ
        final_system_prompt = system_prompt + "\n\n" + context

        # APIå‘¼ã³å‡ºã—
        try:
            messages_for_api = [
                {"role": "system", "content": final_system_prompt},
                *[
                    {"role": m["role"], "content": m["content"]}
                    for m in st.session_state.messages if m.get("role") in ["user", "assistant"]
                ]
            ]
            stream = client.chat.completions.create(
                model="gpt-4o",
                messages=messages_for_api, # type: ignore
                stream=True,
            )
            for chunk in stream:
                full_response += (chunk.choices[0].delta.content or "")
                message_placeholder.markdown(full_response + "â–Œ")
            message_placeholder.markdown(full_response)

        except Exception as e:
            st.error(f"AIã¨ã®é€šä¿¡ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            full_response = "ç”³ã—è¨³ã‚ã‚Šã¾ã›ã‚“ã€å¿œç­”ã‚’ç”Ÿæˆã§ãã¾ã›ã‚“ã§ã—ãŸã€‚"

    # ã‚¢ãƒ‰ãƒã‚¤ã‚¹ã®å¿œç­”ã‚’å±¥æ­´ã«è¿½åŠ 
    st.session_state.messages.append({
        "role": "assistant",
        "content": full_response,
        "sources": [],
        "id": str(uuid.uuid4()),
        "offer_request": False,
        "request_sent": True,
        "coaching_mode": False,
    })


# --- ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ã®å‡¦ç† ---
if prompt := st.chat_input("ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„..."):
    # ã‚³ãƒ¼ãƒãƒ³ã‚°ãƒ¢ãƒ¼ãƒ‰ã®å‡¦ç†
    if st.session_state.get("coaching_mode", False):
        log_content = f"[ãƒ¦ãƒ¼ã‚¶ãƒ¼ç¢ºèªæ¸ˆ] {prompt}"
        log_request(log_content)
        st.session_state.coaching_mode = False
        st.session_state.messages.append({"role": "user", "content": prompt, "id": str(uuid.uuid4())})
        st.session_state.messages.append({
            "role": "assistant",
            "content": f"ã€Œ{prompt}ã€ã ã­ã€‚OKã€ã“ã®å†…å®¹ã§ã—ã‚…ã‚“ã•ã‚“ã«é€ã£ã¦ãŠãã­ï¼",
            "id": str(uuid.uuid4())
        })
        st.rerun()

    # ã‚¢ãƒ‰ãƒã‚¤ã‚¹ãƒ¢ãƒ¼ãƒ‰ã®å‡¦ç†
    if st.session_state.get("advice_mode", False):
        log_request(prompt)
        st.session_state.advice_mode = False
        st.session_state.messages.append({"role": "user", "content": prompt, "id": str(uuid.uuid4())})
        st.session_state.messages.append({
            "role": "assistant",
            "content": f"ã€Œ{prompt}ã€ã ã­ã€‚OKã€ã“ã®å†…å®¹ã§ã—ã‚…ã‚“ã•ã‚“ã«é€ã£ã¦ãŠãã­ï¼",
            "id": str(uuid.uuid4())
        })
        st.rerun()

    # é€šå¸¸ã®å¿œç­”å‡¦ç†
    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å±¥æ­´ã«è¿½åŠ ãƒ»è¡¨ç¤º
    st.session_state.messages.append({"role": "user", "content": prompt, "id": str(uuid.uuid4())})
    with st.chat_message("user"):
        st.markdown(prompt)

    # ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã®å¿œç­”ã‚’ç”Ÿæˆãƒ»ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°è¡¨ç¤º
    with st.chat_message("assistant", avatar="assets/avatar.png"):
        message_placeholder = st.empty()
        full_response = ""
        
        # --- çŸ¥è­˜ãƒ™ãƒ¼ã‚¹ã‹ã‚‰é–¢é€£æƒ…å ±ã‚’æ¤œç´¢ ---
        context = ""
        source_docs = []
        offer_shun_request = False

        if db:
            try:
                docs_with_scores = db.similarity_search_with_score(prompt, k=5)
                if docs_with_scores and docs_with_scores[0][1] <= SIMILARITY_THRESHOLD:
                    source_docs = docs_with_scores
                    context += "--- é–¢é€£æƒ…å ± ---\n"
                    for doc, score in source_docs:
                        context += doc.page_content + "\n\n"
                else:
                    offer_shun_request = True
                    context = "--- é–¢é€£æƒ…å ± ---\nãªã—"
                    # å›ç­”ã§ããªã„ã¨åˆ¤æ–­ã—ãŸæ™‚ç‚¹ã§ã€ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’è¦ç´„ã—ã¦ãƒ­ã‚°ã«è¨˜éŒ²
                    rephrase_and_log_request(prompt)
            except Exception as e:
                st.warning(f"çŸ¥è­˜ãƒ™ãƒ¼ã‚¹ã®æ¤œç´¢ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")

        # --- ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®æº–å‚™ ---
        try:
            with open("docs/system_prompt.md", "r", encoding="utf-8") as f:
                system_prompt = f.read()
        except FileNotFoundError:
            st.warning("docs/system_prompt.md ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
            system_prompt = "You are a helpful assistant."

        final_system_prompt = system_prompt
        if context:
            final_system_prompt += "\n\n" + context

        # --- APIå‘¼ã³å‡ºã—ã¨ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚° ---
        try:
            messages_for_api = [
                {"role": "system", "content": final_system_prompt},
                *[
                    {"role": m["role"], "content": m["content"]}
                    for m in st.session_state.messages
                ]
            ]
            
            stream = client.chat.completions.create(
                model="gpt-4o",
                messages=messages_for_api,
                stream=True,
            )
            for chunk in stream:
                full_response += (chunk.choices[0].delta.content or "")
                message_placeholder.markdown(full_response + "â–Œ")
            message_placeholder.markdown(full_response)

        except Exception as e:
            st.error(f"AIã¨ã®é€šä¿¡ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            full_response = "ç”³ã—è¨³ã‚ã‚Šã¾ã›ã‚“ã€å¿œç­”ã‚’ç”Ÿæˆã§ãã¾ã›ã‚“ã§ã—ãŸã€‚"

        # --- å‚ç…§å…ƒã®è¡¨ç¤º ---
        if source_docs:
            with st.expander("å‚ç…§å…ƒãƒ•ã‚¡ã‚¤ãƒ«"):
                for i, (doc, score) in enumerate(source_docs):
                    st.markdown(f"**ãƒ•ã‚¡ã‚¤ãƒ«å:** `{doc.metadata.get('source', 'N/A')}`")
                    st.markdown(f"**é¸æŠç†ç”±:** ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã¨å†…å®¹ãŒé¡ä¼¼ã—ã¦ã„ã‚‹ãŸã‚ (é¡ä¼¼åº¦ã‚¹ã‚³ã‚¢: {score:.4f})")
                    st.text_area("å‚ç…§ç®‡æ‰€:", value=doc.page_content, height=100, disabled=True, key=f"stream_source_{i}")

    # --- å®Œå…¨ãªå¿œç­”ã‚’ã‚»ãƒƒã‚·ãƒ§ãƒ³å±¥æ­´ã«è¿½åŠ  ---
    st.session_state.messages.append({
        "role": "assistant",
        "content": full_response,
        "sources": source_docs,
        "id": str(uuid.uuid4()),
        "offer_request": offer_shun_request,
        "request_sent": False,
        "coaching_mode": False
    })
    
    # ä¼šè©±ã®æœ€å¾Œã«è‡ªå‹•ã§ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«ã™ã‚‹ãŸã‚ã®JavaScriptãƒãƒƒã‚¯
    components.html(
        "<script>window.scrollTo(0, document.body.scrollHeight);</script>",
        height=0
    ) 