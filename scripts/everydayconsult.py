import streamlit as st
import os
import json
from openai import OpenAI
from langchain_openai import OpenAIEmbeddings
from langchain_community.vectorstores import FAISS
import uuid
from datetime import datetime
import streamlit.components.v1 as components

def generate_source_reasons(client, prompt, docs_with_scores):
    """
    å„å‚ç…§ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãŒãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«æœ¬å½“ã«é–¢é€£ã—ã¦ã„ã‚‹ã‹ã‚’åˆ¤æ–­ã—ã€
    é–¢é€£ã—ã¦ã„ã‚‹å ´åˆã¯ãã®ç†ç”±ã‚’ã€ã—ã¦ã„ãªã„å ´åˆã¯ãã®æ—¨ã‚’è¿”ã—ã¾ã™ã€‚
    """
    if not docs_with_scores:
        return []

    content_list = []
    for i, (doc, score) in enumerate(docs_with_scores):
        content_list.append(f"<{i+1}>\n{doc.page_content}\n</{i+1}>")
    
    formatted_chunks = "\n\n".join(content_list)

    system_prompt = "ã‚ãªãŸã¯ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã¨è¤‡æ•°ã®ãƒ†ã‚­ã‚¹ãƒˆæ–­ç‰‡ã®é–¢ä¿‚æ€§ã‚’åˆ†æã™ã‚‹å°‚é–€å®¶ã§ã™ã€‚å„ãƒ†ã‚­ã‚¹ãƒˆæ–­ç‰‡ãŒãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«æœ¬å½“ã«é–¢é€£ã—ã¦ã„ã‚‹ã‹ã‚’å³å¯†ã«åˆ¤æ–­ã—ã€é–¢é€£ã—ã¦ã„ã‚‹å ´åˆã¯ãã®æ ¸å¿ƒçš„ãªç†ç”±ã‚’ã€é–¢é€£ã—ã¦ã„ãªã„å ´åˆã¯ãã®æ—¨ã‚’æ˜ç¢ºã«ç¤ºã—ã¦ãã ã•ã„ã€‚"
    
    user_message = f"""ä»¥ä¸‹ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã¨ã€ãã‚Œã«é–¢é€£ã™ã‚‹å¯èƒ½æ€§ã®ã‚ã‚‹ãƒ†ã‚­ã‚¹ãƒˆæ–­ç‰‡ãƒªã‚¹ãƒˆã‚’èª­ã‚“ã§ãã ã•ã„ã€‚

# ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•
{prompt}

# ãƒ†ã‚­ã‚¹ãƒˆæ–­ç‰‡ãƒªã‚¹ãƒˆ
{formatted_chunks}

# æŒ‡ç¤º
å„ãƒ†ã‚­ã‚¹ãƒˆæ–­ç‰‡ã«ã¤ã„ã¦ã€ä»¥ä¸‹ã®ã©ã¡ã‚‰ã‹ã®å½¢å¼ã§å›ç­”ã—ã¦ãã ã•ã„ã€‚
1.  **æœ¬å½“ã«é–¢é€£ã—ã¦ã„ã‚‹å ´åˆ:** `ç†ç”±: [ã“ã“ã«å…·ä½“çš„ãªç†ç”±ã‚’1æ–‡ã§è¨˜è¿°]`
2.  **é–¢é€£ã—ã¦ã„ãªã„å ´åˆ:** `ç†ç”±: [IRRELEVANT]`

ç•ªå·ã‚’ä»˜ã‘ã¦ãƒªã‚¹ãƒˆå½¢å¼ã§å‡ºåŠ›ã—ã€ä»–ã®ä½™è¨ˆãªè¨€è‘‰ã¯å«ã‚ãªã„ã§ãã ã•ã„ã€‚

ä¾‹:
1. ç†ç”±: ã€‡ã€‡ã¨ã„ã†èª²é¡Œã«å¯¾ã™ã‚‹å…·ä½“çš„ãªè§£æ±ºç­–ãŒç¤ºã•ã‚Œã¦ã„ã‚‹ãŸã‚ã€‚
2. ç†ç”±: [IRRELEVANT]
3. ç†ç”±: è³ªå•å†…ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã€Œâ–³â–³ã€ã«é–¢ã™ã‚‹è©³ç´°ãªèƒŒæ™¯ã‚’èª¬æ˜ã—ã¦ã„ã‚‹ãŸã‚ã€‚
"""
    try:
        response = client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_message},
            ],
            temperature=0,
            max_tokens=500,
        )
        reasons_text = response.choices[0].message.content
        reasons = []
        for line in reasons_text.strip().split('\n'):
            if 'ç†ç”±: ' in line:
                reason = line.split('ç†ç”±: ', 1)[1].strip()
                reasons.append(reason)
        
        if len(reasons) == len(docs_with_scores):
            return reasons
        else:
            # ãƒ‘ãƒ¼ã‚¹å¤±æ•—æ™‚ã¯å…¨ã¦ç„¡é–¢ä¿‚ã¨ã—ã¦æ‰±ã†
            return ["[IRRELEVANT]"] * len(docs_with_scores)
    except Exception:
        return ["[IRRELEVANT]"] * len(docs_with_scores)


# --- å®šæ•° ---
SIMILARITY_THRESHOLD = 0.7 # é¡ä¼¼åº¦è©•ä¾¡ã®ã—ãã„å€¤ã‚’å†åº¦æœ‰åŠ¹åŒ–
FEEDBACK_LOG_FILE = "feedback.log"

def log_feedback(message_id, user_prompt, assistant_response, feedback):
    """
    ä¼šè©±ã®ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«è¨˜éŒ²ã—ã¾ã™ã€‚
    """
    timestamp = datetime.now().isoformat()
    log_entry = {
        "timestamp": timestamp,
        "message_id": message_id,
        "user_prompt": user_prompt,
        "assistant_response": assistant_response,
        "feedback": feedback
    }
    with open(FEEDBACK_LOG_FILE, "a", encoding="utf-8") as f:
        f.write(json.dumps(log_entry, ensure_ascii=False) + "\n")

# --- åˆæœŸè¨­å®š ---
st.title("ã„ã¤ã§ã‚‚ã—ã‚…ã‚“ã•ã‚“")

# Streamlitã®secretsã‹ã‚‰APIã‚­ãƒ¼ã‚’è¨­å®š
try:
    api_key = st.secrets["OPENAI_API_KEY"]
    client = OpenAI(api_key=api_key)
except KeyError:
    st.error("OpenAI APIã‚­ãƒ¼ãŒ.streamlit/secrets.tomlã«è¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
    st.stop()

# --- FAISSã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®ãƒ­ãƒ¼ãƒ‰ ---
FAISS_INDEX_PATH = "data/faiss_index"

@st.cache_resource
def load_faiss_index(path):
    """FAISSã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’åˆ©ç”¨ï¼‰"""
    try:
        embeddings = OpenAIEmbeddings()
        return FAISS.load_local(path, embeddings, allow_dangerous_deserialization=True)
    except Exception as e:
        st.error(f"çŸ¥è­˜ãƒ™ãƒ¼ã‚¹ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
        return None

db = load_faiss_index(FAISS_INDEX_PATH)

# ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–
if "messages" not in st.session_state:
    st.session_state.messages = [{
        "role": "assistant",
        "content": "åƒ•ã¯ã—ã‚…ã‚“ã•ã‚“ã®ã‚¯ãƒ­ãƒ¼ãƒ³ã§ã™ã€‚ã—ã‚…ã‚“ã•ã‚“ãŒæ•™ãˆã¦ãã‚ŒãŸæƒ…å ±ã‚’å…ƒã«ã‚ãªãŸã®è³ªå•ã«ç­”ãˆã¡ã‚ƒã†ã‚ˆï¼å¼•ãå¯„ã›ã®æ³•å‰‡ãƒ»ã‚ªãƒ¼ãƒ€ãƒ¼ãƒãƒ¼ãƒˆã‚’å­¦ã¶ä¸­ã§ç–‘å•ã‚„äººç”Ÿç›¸è«‡ãªã©ã‚ã‚Œã°ãªã‚“ãªã‚Šãƒãƒ£ãƒƒãƒˆã‹ã‚‰æ•™ãˆã¦ãã ã•ã„ï¼\n\nâ€»ã‚ãªãŸãŒè³ªå•ã—ãŸã“ã¨ã¯ã„ã‹ãªã‚‹ã“ã¨ã§ã‚ã£ã¦ã‚‚ã€ã—ã‚…ã‚“ã•ã‚“ã‚„ä»–ã®äººã«ã¯è¦‹ãˆãªã„ã‹ã‚‰ã€å®‰å¿ƒã—ã¦ã­ï¼",
        "id": str(uuid.uuid4()),
    }]
if "scroll_to_bottom" not in st.session_state:
    st.session_state.scroll_to_bottom = False
if 'feedback_given' not in st.session_state:
    st.session_state.feedback_given = {}

# --- ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®è¡¨ç¤º ---
for i, msg in enumerate(st.session_state.messages):
    avatar_url = "assets/avatar.png" if msg["role"] == "assistant" else "user"
    with st.chat_message(msg["role"], avatar=avatar_url):
        st.markdown(msg["content"])
        
        # --- ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯æ©Ÿèƒ½ ---
        if msg["role"] == "assistant":
            feedback_status = st.session_state.feedback_given.get(msg["id"])
            
            if not feedback_status:
                cols = st.columns([1, 1, 8])
                with cols[0]:
                    if st.button("ğŸ‘", key=f"good_{msg['id']}", help="ã“ã®å›ç­”ã«æº€è¶³"):
                        user_prompt = ""
                        if i > 0 and st.session_state.messages[i-1]["role"] == "user":
                            user_prompt = st.session_state.messages[i-1]["content"]
                        log_feedback(msg['id'], user_prompt, msg['content'], "good")
                        st.session_state.feedback_given[msg['id']] = 'good'
                        st.toast("ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã™ï¼")
                        st.rerun()
                
                with cols[1]:
                    if st.button("ğŸ‘", key=f"bad_{msg['id']}", help="ã“ã®å›ç­”ã«ä¸æº€"):
                        user_prompt = ""
                        if i > 0 and st.session_state.messages[i-1]["role"] == "user":
                            user_prompt = st.session_state.messages[i-1]["content"]
                        log_feedback(msg['id'], user_prompt, msg['content'], "bad")
                        st.session_state.feedback_given[msg['id']] = 'bad'
                        st.toast("æ”¹å–„ã®ãŸã‚ã®ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã€æ„Ÿè¬ã—ã¾ã™ã€‚")
                        st.rerun()
            else:
                st.markdown(
                    f"<span style='color: #4A4A4A;'>{'ğŸ‘' if feedback_status == 'good' else 'ğŸ‘'} ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯æ¸ˆã¿</span>", 
                    unsafe_allow_html=True
                )

        # ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã§ã€ã‹ã¤å‚ç…§å…ƒæƒ…å ±ãŒã‚ã‚‹å ´åˆ
        if msg["role"] == "assistant" and "sources" in msg and msg["sources"]:
            with st.expander("å‚ç…§å…ƒãƒ•ã‚¡ã‚¤ãƒ«"):
                for item in msg["sources"]:
                    doc = item["doc"]
                    score = item["score"]
                    reason = item["reason"]
                    
                    st.markdown(f"**ãƒ•ã‚¡ã‚¤ãƒ«å:** `{doc.metadata.get('source', 'N/A')}`")
                    st.markdown(f"**é¸æŠç†ç”±:** {reason} (é¡ä¼¼åº¦ã‚¹ã‚³ã‚¢: {score:.4f})")
                    
                    # ã‚³ãƒ³ãƒ†ãƒŠã‚’ä½¿ã£ã¦å‚ç…§ç®‡æ‰€ã‚’ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«å¯èƒ½ã«
                    content_html = f"""
                        <div style="background-color: #262730; border-radius: 5px; padding: 10px; height: 150px; overflow-y: auto; border: 1px solid #333;">
                            <pre style="white-space: pre-wrap; word-wrap: break-word; color: #FAFAFA; font-family: 'Source Code Pro', monospace;">{doc.page_content}</pre>
                        </div>
                    """
                    components.html(content_html, height=170)
                    st.divider()

# --- ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‹ã‚‰ã®å…¥åŠ› ---
if prompt := st.chat_input("ã“ã“ã«ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„"):
    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å±¥æ­´ã«è¿½åŠ 
    st.session_state.messages.append({"role": "user", "content": prompt, "id": str(uuid.uuid4())})
    
    # ç”»é¢ã«ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¡¨ç¤º
    with st.chat_message("user"):
        st.markdown(prompt)

    # --- AIã®å¿œç­”ç”Ÿæˆ ---
    with st.chat_message("assistant", avatar="assets/avatar.png"):
        message_placeholder = st.empty()
        full_response = ""

        # --- çŸ¥è­˜ãƒ™ãƒ¼ã‚¹ã‹ã‚‰é–¢é€£æƒ…å ±ã‚’æ¤œç´¢ ---
        context = ""
        source_docs_with_reasons = []
        is_relevant_info_found = False
        if db:
            try:
                # ã‚¹ãƒ†ãƒƒãƒ—1: é¡ä¼¼åº¦ã‚¹ã‚³ã‚¢ã«åŸºã¥ãã€å€™è£œã‚’æ¤œç´¢
                docs_with_scores = db.similarity_search_with_score(prompt, k=5)
                
                if docs_with_scores and docs_with_scores[0][1] <= SIMILARITY_THRESHOLD:
                    
                    # ã‚¹ãƒ†ãƒƒãƒ—2: AIã«ã‚ˆã‚‹æ„å‘³çš„ãªé–¢é€£æ€§ãƒã‚§ãƒƒã‚¯(é–¢æ‰€)
                    reasons = generate_source_reasons(client, prompt, docs_with_scores)
                    
                    # ã‚¹ãƒ†ãƒƒãƒ—3:æœ¬å½“ã«é–¢é€£ã™ã‚‹ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã ã‘ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
                    relevant_sources = []
                    for (doc, score), reason in zip(docs_with_scores, reasons):
                        if reason != "[IRRELEVANT]":
                            relevant_sources.append({
                                "doc": doc,
                                "score": score,
                                "reason": reason
                            })
                    
                    # ã‚¹ãƒ†ãƒƒãƒ—4: é–¢é€£ã™ã‚‹ã‚‚ã®ãŒ1ã¤ã§ã‚‚ã‚ã‚Œã°ã€ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’æ§‹ç¯‰
                    if relevant_sources:
                        is_relevant_info_found = True
                        source_docs_with_reasons = relevant_sources
                        context += "--- é–¢é€£æƒ…å ± ---\n"
                        for item in source_docs_with_reasons:
                            context += item["doc"].page_content + "\n\n"

            except Exception as e:
                st.warning(f"çŸ¥è­˜ãƒ™ãƒ¼ã‚¹ã®æ¤œç´¢ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")

        # --- ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®æº–å‚™ ---
        try:
            with open("docs/system_prompt.md", "r", encoding="utf-8") as f:
                system_prompt = f.read()
        except FileNotFoundError:
            st.warning("docs/system_prompt.md ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
            system_prompt = "You are a helpful assistant."

        final_system_prompt = system_prompt
        # é–¢é€£æƒ…å ±ãŒè¦‹ã¤ã‹ã£ãŸå ´åˆã®ã¿ã€ãã®æƒ…å ±ã‚’ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«è¿½åŠ 
        if is_relevant_info_found:
            final_system_prompt += "\n\n" + context
        else:
            # è¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯ã€Œãªã—ã€ã¨ã„ã†æ˜ç¢ºãªä¿¡å·ã‚’é€ã‚‹
            final_system_prompt += "\n\n--- é–¢é€£æƒ…å ± ---\nãªã—"

        # --- APIå‘¼ã³å‡ºã—ã¨ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚° ---
        try:
            messages_for_api = [
                {"role": "system", "content": final_system_prompt},
                *[
                    {"role": m["role"], "content": m["content"]}
                    for m in st.session_state.messages
                ]
            ]
            
            stream = client.chat.completions.create(
                model="gpt-4o",
                messages=messages_for_api,
                stream=True,
            )
            for chunk in stream:
                full_response += (chunk.choices[0].delta.content or "")
                message_placeholder.markdown(full_response + "â–Œ")
            message_placeholder.markdown(full_response)

        except Exception as e:
            st.error(f"AIã¨ã®é€šä¿¡ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            full_response = "ç”³ã—è¨³ã‚ã‚Šã¾ã›ã‚“ã€å¿œç­”ã‚’ç”Ÿæˆã§ãã¾ã›ã‚“ã§ã—ãŸã€‚"

    # --- å®Œå…¨ãªå¿œç­”ã‚’ã‚»ãƒƒã‚·ãƒ§ãƒ³å±¥æ­´ã«è¿½åŠ  ---
    st.session_state.messages.append({
        "role": "assistant",
        "content": full_response,
        "sources": source_docs_with_reasons,
        "id": str(uuid.uuid4()),
    })

    # --- è‡ªå‹•ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«ã¨å†å®Ÿè¡Œ ---
    st.session_state.scroll_to_bottom = True
    st.rerun()

# --- è‡ªå‹•ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«ã®å®Ÿè¡Œ ---
if st.session_state.get("scroll_to_bottom"):
    components.html(
        "<script>window.scrollTo(0, document.body.scrollHeight);</script>",
        height=0
    )
    st.session_state.scroll_to_bottom = False 